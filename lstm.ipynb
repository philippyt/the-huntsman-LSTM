{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ordijegeren.csv\", header=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               0\n0             en\n1       kvelende\n2           varm\n3      sommerdag\n4            det\n...          ...\n2139         øye\n2140          på\n2141         den\n2142       hvite\n2143  skyggeluen\n\n[2144 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kvelende</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>varm</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sommerdag</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2139</th>\n      <td>øye</td>\n    </tr>\n    <tr>\n      <th>2140</th>\n      <td>på</td>\n    </tr>\n    <tr>\n      <th>2141</th>\n      <td>den</td>\n    </tr>\n    <tr>\n      <th>2142</th>\n      <td>hvite</td>\n    </tr>\n    <tr>\n      <th>2143</th>\n      <td>skyggeluen</td>\n    </tr>\n  </tbody>\n</table>\n<p>2144 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "text = ' '.join(df[0].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'og': 1,\n 'det': 2,\n 'er': 3,\n 'en': 4,\n 'jeg': 5,\n 'du': 6,\n 'i': 7,\n 'på': 8,\n 'til': 9,\n 'å': 10,\n 'som': 11,\n 'med': 12,\n 'ikke': 13,\n 'har': 14,\n 'seg': 15,\n 'for': 16,\n 'av': 17,\n 'han': 18,\n 'meg': 19,\n 'jegor': 20,\n 'om': 21,\n 'at': 22,\n 'men': 23,\n 'et': 24,\n 'den': 25,\n 'deg': 26,\n 'så': 27,\n 'hun': 28,\n 'pelageja': 29,\n 'bare': 30,\n 'ser': 31,\n 'går': 32,\n 'sier': 33,\n 'vlasytsj': 34,\n 'kan': 35,\n 'jo': 36,\n 'fra': 37,\n 'noe': 38,\n 'de': 39,\n 'sin': 40,\n 'ham': 41,\n 'eller': 42,\n 'var': 43,\n 'hva': 44,\n 'ut': 45,\n 'ha': 46,\n 'selv': 47,\n 'aldri': 48,\n 'helt': 49,\n 'etter': 50,\n 'hans': 51,\n 'over': 52,\n 'opp': 53,\n 'vi': 54,\n 'gjøre': 55,\n 'får': 56,\n 'også': 57,\n 'blir': 58,\n 'når': 59,\n 'eneste': 60,\n 'kunne': 61,\n 'mann': 62,\n 'mens': 63,\n 'holder': 64,\n 'lenge': 65,\n 'siden': 66,\n 'gang': 67,\n 'se': 68,\n 'fått': 69,\n 'være': 70,\n 'tar': 71,\n 'skyggeluen': 72,\n 'enn': 73,\n 'farvel': 74,\n 'alt': 75,\n 'skulle': 76,\n 'står': 77,\n 'tier': 78,\n 'hånden': 79,\n 'blikket': 80,\n 'her': 81,\n 'sammen': 82,\n 'følger': 83,\n 'sett': 84,\n 'full': 85,\n 'hele': 86,\n 'tiden': 87,\n 'egentlig': 88,\n 'mellom': 89,\n 'landsbyen': 90,\n 'vet': 91,\n 'ville': 92,\n 'jeger': 93,\n 'forstår': 94,\n 'kvinnfolk': 95,\n 'bort': 96,\n 'oss': 97,\n 'mot': 98,\n 'komme': 99,\n 'vil': 100,\n 'fjerne': 101,\n 'ganske': 102,\n 'tid': 103,\n 'strekker': 104,\n 'horisonten': 105,\n 'ansiktet': 106,\n 'annen': 107,\n 'stille': 108,\n 'jegeren': 109,\n 'like': 110,\n 'få': 111,\n 'ned': 112,\n 'hvordan': 113,\n 'gå': 114,\n 'videre': 115,\n 'henne': 116,\n 'din': 117,\n 'øynene': 118,\n 'litt': 119,\n 'fordi': 120,\n 'to': 121,\n 'fast': 122,\n 'hvis': 123,\n 'satt': 124,\n 'liten': 125,\n 'andre': 126,\n 'driver': 127,\n 'slags': 128,\n 'dette': 129,\n 'noen': 130,\n 'da': 131,\n 'samme': 132,\n 'begynner': 133,\n 'før': 134,\n 'kjærlighet': 135,\n 'slutt': 136,\n 'ny': 137,\n 'nå': 138,\n 'tilbake': 139,\n 'bli': 140,\n 'igjen': 141,\n 'ubevegelig': 142,\n 'rød': 143,\n 'bruker': 144,\n 'høye': 145,\n 'støvler': 146,\n 'langsomt': 147,\n 'høyre': 148,\n 'grønne': 149,\n 'grunn': 150,\n 'heten': 151,\n 'sitter': 152,\n 'godseier': 153,\n 'vært': 154,\n 'skulderen': 155,\n 'orrhane': 156,\n 'begge': 157,\n 'hanene': 158,\n 'spent': 159,\n 'stykke': 160,\n 'foran': 161,\n 'ellers': 162,\n 'plutselig': 163,\n 'veien': 164,\n 'smiler': 165,\n 'stanser': 166,\n 'geværet': 167,\n 'vår': 168,\n 'dem': 169,\n 'arbeid': 170,\n 'ja': 171,\n 'skritt': 172,\n 'taushet': 173,\n 'skulderbladene': 174,\n 'beveger': 175,\n 'kom': 176,\n 'innom': 177,\n 'hytten': 178,\n 'drikke': 179,\n 'gikk': 180,\n 'ventet': 181,\n 'nesten': 182,\n 'slik': 183,\n 'fall': 184,\n 'skal': 185,\n 'hos': 186,\n 'likevel': 187,\n 'herren': 188,\n 'fortsetter': 189,\n 'snakke': 190,\n 'sted': 191,\n 'hvorfor': 192,\n 'røde': 193,\n 'bortskjemt': 194,\n 'uten': 195,\n 'ordentlig': 196,\n 'sagt': 197,\n 'bedre': 198,\n 'skitt': 199,\n 'mye': 200,\n 'dag': 201,\n 'hatt': 202,\n 'finere': 203,\n 'omkring': 204,\n 'vilt': 205,\n 'kunnet': 206,\n 'kommer': 207,\n 'heller': 208,\n 'gjelder': 209,\n 'tenke': 210,\n 'hestehandel': 211,\n 'marked': 212,\n 'store': 213,\n 'godt': 214,\n 'måte': 215,\n 'gråte': 216,\n 'gråter': 217,\n 'snur': 218,\n 'stor': 219,\n 'allerede': 220,\n 'giftet': 221,\n 'umulig': 222,\n 'kone': 223,\n 'lever': 224,\n 'ryggen': 225,\n 'hvert': 226,\n 'greven': 227,\n 'budeie': 228,\n 'imot': 229,\n 'lille': 230,\n 'fornøyelse': 231,\n 'tre': 232,\n 'forsvinner': 233,\n 'spør': 234,\n 'gir': 235,\n 'må': 236,\n 'reiser': 237,\n 'inn': 238,\n 'hunden': 239,\n 'hennes': 240,\n 'kvelende': 241,\n 'varm': 242,\n 'sommerdag': 243,\n 'sky': 244,\n 'himmelen': 245,\n 'brunsvidde': 246,\n 'gresset': 247,\n 'mistet': 248,\n 'håp': 249,\n 'regn': 250,\n 'grønt': 251,\n 'skogen': 252,\n 'lytter': 253,\n 'venter': 254,\n 'svake': 255,\n 'suset': 256,\n 'begynnende': 257,\n 'regnvær': 258,\n 'langs': 259,\n 'kanten': 260,\n 'hugstfelt': 261,\n 'høy': 262,\n 'smalskuldret': 263,\n 'førtiårsalderen': 264,\n 'skjorte': 265,\n 'lappete': 266,\n 'ridebukser': 267,\n 'typen': 268,\n 'godseierne': 269,\n 'vaggende': 270,\n 'gange': 271,\n 'all': 272,\n 'verdens': 273,\n 'rådighet': 274,\n 'hugtsfeltet': 275,\n 'venstre': 276,\n 'bølgende': 277,\n 'hav': 278,\n 'moden': 279,\n 'rug': 280,\n 'svetter': 281,\n 'voldsomme': 282,\n 'velformede': 283,\n 'hode': 284,\n 'hvit': 285,\n 'skyggelue': 286,\n 'kjekt': 287,\n 'snei': 288,\n 'tydeligvis': 289,\n 'gave': 290,\n 'gavmilde': 291,\n 'hjørne': 292,\n 'slengt': 293,\n 'jakttaske': 294,\n 'inneholder': 295,\n 'sammenklemt': 296,\n 'dobbeltløpet': 297,\n 'haglgevær': 298,\n 'mysende': 299,\n 'gamle': 300,\n 'utmagrede': 301,\n 'hund': 302,\n 'løper': 303,\n 'snuser': 304,\n 'buskene': 305,\n 'utdødd': 306,\n 'virker': 307,\n 'levende': 308,\n 'gått': 309,\n 'dekning': 310,\n 'hører': 311,\n 'lav': 312,\n 'stemme': 313,\n 'kalle': 314,\n 'rykker': 315,\n 'rynkende': 316,\n 'bryn': 317,\n 'ved': 318,\n 'skutt': 319,\n 'jorden': 320,\n 'ung': 321,\n 'kvinne': 322,\n 'tredveårsalderen': 323,\n 'blekt': 324,\n 'ansikt': 325,\n 'sigd': 326,\n 'unnselig': 327,\n 'forsøker': 328,\n 'tak': 329,\n 'forsiktig': 330,\n 'slipper': 331,\n 'pekefingeren': 332,\n 'hm': 333,\n 'havnet': 334,\n 'del': 335,\n 'kvinnfolkene': 336,\n 'landsby': 337,\n 'sendt': 338,\n 'hit': 339,\n 'arbeide': 340,\n 'nødt': 341,\n 'jaja': 342,\n 'mumler': 343,\n 'tyve': 344,\n 'tredve': 345,\n 'ømt': 346,\n 'påskeuken': 347,\n 'vann': 348,\n 'snurten': 349,\n 'tilstand': 350,\n 'gangen': 351,\n 'påsken': 352,\n 'gal': 353,\n 'bannet': 354,\n 'svor': 355,\n 'slo': 356,\n 'vei': 357,\n 'stirret': 358,\n 'hadde': 359,\n 'kommet': 360,\n 'imellom': 361,\n 'alle': 362,\n 'særlig': 363,\n 'hjemme': 364,\n 'huset': 365,\n 'lovlig': 366,\n 'ekteskap': 367,\n 'trekke': 368,\n 'skuldrene': 369,\n 'nei': 370,\n 'has': 371,\n 'fin': 372,\n 'sette': 373,\n 'hvile': 374,\n 'fjollet': 375,\n 'bønnlig': 376,\n 'flommer': 377,\n 'lykke': 378,\n 'nærheten': 379,\n 'mannen': 380,\n 'sitte': 381,\n 'kanskje': 382,\n 'likeglad': 383,\n 'tone': 384,\n 'velger': 385,\n 'granbusker': 386,\n 'henger': 387,\n 'midt': 388,\n 'solsteken': 389,\n 'ifra': 390,\n 'skjuler': 391,\n 'munnen': 392,\n 'skammer': 393,\n 'vise': 394,\n 'lykkelig': 395,\n 'par': 396,\n 'minutter': 397,\n 'fullstendig': 398,\n 'stikke': 399,\n 'hjemom': 400,\n 'grunnen': 401,\n 'sukker': 402,\n 'tørker': 403,\n 'svette': 404,\n 'pannen': 405,\n 'ermet': 406,\n 'ingen': 407,\n 'hensikt': 408,\n 'stikker': 409,\n 'time': 410,\n 'tårer': 411,\n 'ugreie': 412,\n 'bo': 413,\n 'altfor': 414,\n 'greier': 415,\n 'seng': 416,\n 'god': 417,\n 'te': 418,\n 'samtaler': 419,\n 'høyverdige': 420,\n 'ting': 421,\n 'kort': 422,\n 'by': 423,\n 'evinnelige': 424,\n 'fattigdom': 425,\n 'sot': 426,\n 'kjegl': 427,\n 'overleve': 428,\n 'keiserlig': 429,\n 'ordre': 430,\n 'leve': 431,\n 'enten': 432,\n 'fyr': 433,\n 'lagt': 434,\n 'hånd': 435,\n 'fornemmelser': 436,\n 'rundt': 437,\n 'hvor': 438,\n 'bor': 439,\n 'dmitrij': 440,\n 'ivanytsj': 441,\n 'leverer': 442,\n 'kjøkken': 443,\n 'mest': 444,\n 'fornøyelses': 445,\n 'skyld': 446,\n 'liksom': 447,\n 'mennesker': 448,\n 'rent': 449,\n 'tidsfordriv': 450,\n 'gjort': 451,\n 'håndverk': 452,\n 'yrke': 453,\n 'ditt': 454,\n 'dumme': 455,\n 'drømmende': 456,\n 'fremfor': 457,\n 'fatte': 458,\n 'menneske': 459,\n 'mener': 460,\n 'altså': 461,\n 'guttestreker': 462,\n 'voksen': 463,\n 'alder': 464,\n 'unyttig': 465,\n 'dagdriver': 466,\n 'virkelig': 467,\n 'beste': 468,\n 'skytteren': 469,\n 'distriktet': 470,\n 'respekterer': 471,\n 'herskapet': 472,\n 'skrevet': 473,\n 'tidsskrift': 474,\n 'mils': 475,\n 'omkrets': 476,\n 'måle': 477,\n 'innsikt': 478,\n 'jaktspørsmål': 479,\n 'skitten': 480,\n 'slitet': 481,\n 'kvelningsfornemmelser': 482,\n 'stolt': 483,\n 'tilværelse': 484,\n 'streife': 485,\n 'skog': 486,\n 'mark': 487,\n 'børse': 488,\n 'bikkje': 489,\n 'børsa': 490,\n 'griper': 491,\n 'fiskestangen': 492,\n 'tørre': 493,\n 'nevene': 494,\n 'drevet': 495,\n 'dradd': 496,\n 'penger': 497,\n 'hendene': 498,\n 'bonde': 499,\n 'først': 500,\n 'smaken': 501,\n 'drive': 502,\n 'jakt': 503,\n 'ljåen': 504,\n 'friheten': 505,\n 'blodet': 506,\n 'arbeidskjerren': 507,\n 'mer': 508,\n 'adelen': 509,\n 'skuespiller': 510,\n 'slår': 511,\n 'kunstart': 512,\n 'duger': 513,\n 'senere': 514,\n 'hverken': 515,\n 'embetsmann': 516,\n 'derfor': 517,\n 'forstå': 518,\n 'dreier': 519,\n 'tydelig': 520,\n 'synd': 521,\n 'bodd': 522,\n 'ulykkelig': 523,\n 'tolv': 524,\n 'år': 525,\n 'denne': 526,\n 'grusomt': 527,\n 'sørgmodig': 528,\n 'sinns': 529,\n 'brummer': 530,\n 'klør': 531,\n 'navnet': 532,\n 'fremmed': 533,\n 'vanlig': 534,\n 'innskrenket': 535,\n 'flest': 536,\n 'ektepar': 537,\n 'fri': 538,\n 'fugl': 539,\n 'gjør': 540,\n 'passer': 541,\n 'arbeidsdyr': 542,\n 'bastsko': 543,\n 'knapt': 544,\n 'rette': 545,\n 'absolutt': 546,\n 'førsteklasses': 547,\n 'blanding': 548,\n 'medlidenhet': 549,\n 'misnøye': 550,\n 'slike': 551,\n 'passe': 552,\n 'viet': 553,\n 'hulke': 554,\n 'høyt': 555,\n 'min': 556,\n 'gode': 557,\n 'vilje': 558,\n 'takke': 559,\n 'grev': 560,\n 'sergej': 561,\n 'pavlytsj': 562,\n 'vielsen': 563,\n 'tålte': 564,\n 'skjøt': 565,\n 'pur': 566,\n 'misunnelse': 567,\n 'skjenket': 568,\n 'hel': 569,\n 'måned': 570,\n 'omtåket': 571,\n 'helst': 572,\n 'gifte': 573,\n 'religion': 574,\n 'hevn': 575,\n 'tok': 576,\n 'livegen': 577,\n 'naturligvis': 578,\n 'svinehell': 579,\n 'simpel': 580,\n 'gift': 581,\n 'bruke': 582,\n 'vettet': 583,\n 'utlevert': 584,\n 'klage': 585,\n 'bære': 586,\n 'gråt': 587,\n 'fikk': 588,\n 'slå': 589,\n 'hodet': 590,\n 'veggen': 591,\n 'hugstfeltet': 592,\n 'flyr': 593,\n 'ender': 594,\n 'små': 595,\n 'prikker': 596,\n 'bak': 597,\n 'skogbrynet': 598,\n 'flytter': 599,\n 'endene': 600,\n 'sommeren': 601,\n 'vinteren': 602,\n 'unge': 603,\n 'barnehjemmet': 604,\n 'flaske': 605,\n 'betaler': 606,\n 'halvannen': 607,\n 'rubel': 608,\n 'måneden': 609,\n 'jaha': 610,\n 'ute': 611,\n 'åkeren': 612,\n 'høres': 613,\n 'svakt': 614,\n 'mollstemt': 615,\n 'sang': 616,\n 'dør': 617,\n 'begynt': 618,\n 'varmt': 619,\n 'onnefolkene': 620,\n 'orker': 621,\n 'synge': 622,\n 'engang': 623,\n 'hytte': 624,\n 'akulina': 625,\n 'bety': 626,\n 'faller': 627,\n 'smak': 628,\n 'fornøyd': 629,\n 'venne': 630,\n 'vær': 631,\n 'tålmodig': 632,\n 'nytter': 633,\n 'kjempe': 634,\n 'skjebne': 635,\n 'visst': 636,\n 'tide': 637,\n 'pratet': 638,\n 'bra': 639,\n 'boltovo': 640,\n 'kvelden': 641,\n 'kaster': 642,\n 'neste': 643,\n 'lavt': 644,\n 'der': 645,\n 'fastende': 646,\n 'falle': 647,\n 'vrang': 648,\n 'setter': 649,\n 'smatter': 650,\n 'vandring': 651,\n 'stående': 652,\n 'ungdommelige': 653,\n 'nakken': 654,\n 'slentrende': 655,\n 'likeglade': 656,\n 'fylt': 657,\n 'ømhet': 658,\n 'dypt': 659,\n 'vemod': 660,\n 'mannens': 661,\n 'magre': 662,\n 'skikkelse': 663,\n 'fortapt': 664,\n 'kjærtegnende': 665,\n 'føler': 666,\n 'gjerne': 667,\n 'si': 668,\n 'forsagt': 669,\n 'bedende': 670,\n 'øyne': 671,\n 'sølvrubel': 672,\n 'deretter': 673,\n 'raskt': 674,\n 'mekanisk': 675,\n 'rubelen': 676,\n 'bortover': 677,\n 'snorrete': 678,\n 'smalner': 679,\n 'tynn': 680,\n 'strek': 681,\n 'ensom': 682,\n 'blek': 683,\n 'statue': 684,\n 'fortaper': 685,\n 'skjorten': 686,\n 'lenger': 687,\n 'skjelnes': 688,\n 'mørke': 689,\n 'fargen': 690,\n 'buksene': 691,\n 'prikk': 692,\n 'ett': 693,\n 'herres': 694,\n 'sees': 695,\n 'vender': 696,\n 'brått': 697,\n 'småskogen': 698,\n 'øyeblikk': 699,\n 'blitt': 700,\n 'borte': 701,\n 'hvisker': 702,\n 'tå': 703,\n 'mulig': 704,\n 'enda': 705,\n 'øye': 706,\n 'hvite': 707}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.texts_to_sequences([text])[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for i in range(1, len(tokenized_text)):\n",
    "    input_sequences.append(tokenized_text[:i+1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "x = padded_input_sequences[:, :-1]\n",
    "y = padded_input_sequences[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2144, 2144)\n",
      "(2144,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=50, input_length=max_len-1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(len(tokenizer.word_index)+1, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 2144, 50)          35400     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 708)               71508     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,308\n",
      "Trainable params: 167,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 60s 883ms/step - loss: 6.1440 - accuracy: 0.0354\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 67s 995ms/step - loss: 5.7098 - accuracy: 0.0448\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 69s 1s/step - loss: 5.6529 - accuracy: 0.0462\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 5.5891 - accuracy: 0.0448\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 75s 1s/step - loss: 5.5164 - accuracy: 0.0448\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 76s 1s/step - loss: 5.4564 - accuracy: 0.0462\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 71s 1s/step - loss: 5.3922 - accuracy: 0.0513\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 66s 989ms/step - loss: 5.3713 - accuracy: 0.0597\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 65s 975ms/step - loss: 5.2737 - accuracy: 0.0616\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 66s 985ms/step - loss: 5.2014 - accuracy: 0.0662\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 64s 951ms/step - loss: 5.1220 - accuracy: 0.0709\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 60s 892ms/step - loss: 5.0307 - accuracy: 0.0779\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 58s 871ms/step - loss: 4.9357 - accuracy: 0.0835\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 58s 870ms/step - loss: 4.8400 - accuracy: 0.0868\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 59s 876ms/step - loss: 4.7467 - accuracy: 0.0942\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 63s 937ms/step - loss: 4.6583 - accuracy: 0.0979\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 59s 875ms/step - loss: 4.5657 - accuracy: 0.1157\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 59s 877ms/step - loss: 4.4738 - accuracy: 0.1185\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 60s 890ms/step - loss: 4.3846 - accuracy: 0.1334\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 64s 958ms/step - loss: 4.2933 - accuracy: 0.1339\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 66s 994ms/step - loss: 4.2027 - accuracy: 0.1479\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 64s 960ms/step - loss: 4.1240 - accuracy: 0.1558\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 64s 949ms/step - loss: 4.0224 - accuracy: 0.1712\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 61s 907ms/step - loss: 3.9293 - accuracy: 0.1768\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 60s 897ms/step - loss: 3.8435 - accuracy: 0.1922\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 60s 895ms/step - loss: 3.7491 - accuracy: 0.2118\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 65s 973ms/step - loss: 3.6549 - accuracy: 0.2285\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 66s 985ms/step - loss: 3.5649 - accuracy: 0.2421\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 69s 1s/step - loss: 3.4714 - accuracy: 0.2607\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 69s 1s/step - loss: 3.3802 - accuracy: 0.2738\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 74s 1s/step - loss: 3.2886 - accuracy: 0.2938\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 3.1957 - accuracy: 0.3116\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 67s 990ms/step - loss: 3.1062 - accuracy: 0.3396\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 71s 1s/step - loss: 3.0182 - accuracy: 0.3465\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 70s 1s/step - loss: 2.9277 - accuracy: 0.3787\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 70s 1s/step - loss: 2.8348 - accuracy: 0.3993\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 71s 1s/step - loss: 2.7482 - accuracy: 0.4198\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 2.6678 - accuracy: 0.4454\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 69s 1s/step - loss: 2.5748 - accuracy: 0.4715\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 71s 1s/step - loss: 2.4906 - accuracy: 0.4888\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 74s 1s/step - loss: 2.4078 - accuracy: 0.5084\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 73s 1s/step - loss: 2.3261 - accuracy: 0.5378\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 73s 1s/step - loss: 2.2430 - accuracy: 0.5555\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 74s 1s/step - loss: 2.1611 - accuracy: 0.5742\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 2.0835 - accuracy: 0.5989\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 2.0062 - accuracy: 0.6147\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.9329 - accuracy: 0.6446\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.8571 - accuracy: 0.6544\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 74s 1s/step - loss: 1.7875 - accuracy: 0.6740\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 71s 1s/step - loss: 1.7194 - accuracy: 0.6847\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 73s 1s/step - loss: 1.6491 - accuracy: 0.7085\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 70s 1s/step - loss: 1.5857 - accuracy: 0.7211\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.5233 - accuracy: 0.7421\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.4623 - accuracy: 0.7542\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.4049 - accuracy: 0.7640\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 70s 1s/step - loss: 1.3508 - accuracy: 0.7785\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 72s 1s/step - loss: 1.2936 - accuracy: 0.7920\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 86s 1s/step - loss: 1.2405 - accuracy: 0.8022\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 86s 1s/step - loss: 1.1933 - accuracy: 0.8120\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 87s 1s/step - loss: 1.1417 - accuracy: 0.8214\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 90s 1s/step - loss: 1.1017 - accuracy: 0.8298\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 87s 1s/step - loss: 1.0537 - accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 86s 1s/step - loss: 1.0132 - accuracy: 0.8517\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 90s 1s/step - loss: 0.9712 - accuracy: 0.8591\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 88s 1s/step - loss: 0.9291 - accuracy: 0.8643\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 87s 1s/step - loss: 0.8884 - accuracy: 0.8755\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 89s 1s/step - loss: 0.8527 - accuracy: 0.8829\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 85s 1s/step - loss: 0.8199 - accuracy: 0.8909\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 86s 1s/step - loss: 0.7877 - accuracy: 0.8946\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 89s 1s/step - loss: 0.7534 - accuracy: 0.8979\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 85s 1s/step - loss: 0.7205 - accuracy: 0.9086\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 86s 1s/step - loss: 0.6919 - accuracy: 0.9160\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 85s 1s/step - loss: 0.6631 - accuracy: 0.9174\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 80s 1s/step - loss: 0.6362 - accuracy: 0.9226\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 66s 985ms/step - loss: 0.6081 - accuracy: 0.9338\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 63s 935ms/step - loss: 0.5828 - accuracy: 0.9361\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 65s 965ms/step - loss: 0.5570 - accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 64s 957ms/step - loss: 0.5342 - accuracy: 0.9464\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 63s 938ms/step - loss: 0.5106 - accuracy: 0.9506\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 67s 995ms/step - loss: 0.4870 - accuracy: 0.9501\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 65s 969ms/step - loss: 0.4826 - accuracy: 0.9552\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 67s 989ms/step - loss: 0.4548 - accuracy: 0.9594\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 62s 927ms/step - loss: 0.4297 - accuracy: 0.9627\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 63s 941ms/step - loss: 0.4105 - accuracy: 0.9664\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 64s 959ms/step - loss: 0.3953 - accuracy: 0.9688\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 64s 956ms/step - loss: 0.3776 - accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 62s 931ms/step - loss: 0.3583 - accuracy: 0.9748\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 85s 1s/step - loss: 0.3423 - accuracy: 0.9795\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.3284 - accuracy: 0.9799\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 91s 1s/step - loss: 0.3146 - accuracy: 0.9823\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 85s 1s/step - loss: 0.3002 - accuracy: 0.9841\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 78s 1s/step - loss: 0.2864 - accuracy: 0.9855\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 88s 1s/step - loss: 0.2740 - accuracy: 0.9869\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 88s 1s/step - loss: 0.2622 - accuracy: 0.9860\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 94s 1s/step - loss: 0.2510 - accuracy: 0.9874\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 80s 1s/step - loss: 0.2394 - accuracy: 0.9911\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 64s 958ms/step - loss: 0.2294 - accuracy: 0.9939\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 62s 930ms/step - loss: 0.2195 - accuracy: 0.9921\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 60s 889ms/step - loss: 0.2095 - accuracy: 0.9939\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 63s 941ms/step - loss: 0.1998 - accuracy: 0.9953\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x27532b72eb0>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 17s 248ms/step - loss: 0.1808 - accuracy: 0.9953\n",
      "accuracy: 99.53%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x, y)\n",
    "print(f\"accuracy: {accuracy * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "def get_random_seed():\n",
    "    random_index = np.random.randint(0, len(text))\n",
    "    return text[random_index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "next_words = 100\n",
    "random_word = get_random_seed()\n",
    "generated_text = generate_text(random_word, next_words, max_len)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: e sommerdag det er en som virkelig av begynt det er som mann en eneste gang har det visst at du ser på meg med å drive med jakt eller driver omkring og helt han han og det da du bare bare går og så vilje i hytten stemme kalle på han og tar de han en annen kunstart da duger han senere hverken til embetsmann eller godseier du venne deg på ditt dumme kvinnfolk og til og sier til og når jeg så er sammen med du til å gjøre som hva slags menneske hva jeg greier meg det driver\n"
     ]
    }
   ],
   "source": [
    "print(f\"text: {generated_text}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
